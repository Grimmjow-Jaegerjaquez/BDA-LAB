{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|integer|squared|\n",
      "+-------+-------+\n",
      "|      1|      1|\n",
      "|      2|      4|\n",
      "|      3|      9|\n",
      "|      4|     16|\n",
      "|      5|     25|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"SquareIntegers\").getOrCreate()\n",
    "\n",
    "# Sample data - Replace this with your actual data\n",
    "data = [(1,), (2,), (3,), (4,), (5,)]\n",
    "\n",
    "# Create a DataFrame from the sample data\n",
    "df = spark.createDataFrame(data, [\"integer\"])\n",
    "\n",
    "# Define a UDF (User Defined Function) to square the integers\n",
    "square_udf = udf(lambda x: x ** 2, IntegerType())\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "result_df = df.withColumn(\"squared\", square_udf(col(\"integer\")))\n",
    "\n",
    "# Show the result\n",
    "result_df.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 9\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, max\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"MaxOfNumbers\").getOrCreate()\n",
    "\n",
    "# Sample data - Replace this with your actual data\n",
    "data = [(1,), (7,), (3,), (9,), (5,)]\n",
    "\n",
    "# Create a DataFrame from the sample data\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "\n",
    "# Find the maximum value\n",
    "max_value = df.agg(max(col(\"number\"))).collect()[0][0]\n",
    "\n",
    "# Show the result\n",
    "print(\"Maximum value:\", max_value)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 3.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"AverageOfNumbers\").getOrCreate()\n",
    "\n",
    "# Sample data - Replace this with your actual data\n",
    "data = [(1,), (2,), (3,), (4,), (5,)]\n",
    "\n",
    "# Create a DataFrame from the sample data\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "\n",
    "# Find the average value\n",
    "average_value = df.agg(avg(col(\"number\"))).collect()[0][0]\n",
    "\n",
    "# Show the result\n",
    "print(\"Average value:\", average_value)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|   BDCQ.SF1AA2CA|2016.06|  1116.386|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2016.09|  1070.874|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2016.12|  1054.408|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.03|  1010.665|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.06|    1233.7|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.09|  1282.436|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.12|   1290.82|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.03|  1412.007|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.06|  1488.055|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.09|  1497.678|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.12|  1570.507|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.03|  1393.749|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.06|  1517.143|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.09|  1381.514|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.12|  1370.985|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.03|  1073.017|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.06|  1131.445|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.09|  1440.101|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.12|  1489.979|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2021.03|  1390.782|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ReadCSV\").getOrCreate()\n",
    "\n",
    "# Read the CSV file into a PySpark DataFrame\n",
    "df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|   BDCQ.SF1AA2CA|2016.06|  1116.386|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2016.09|  1070.874|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2016.12|  1054.408|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.03|  1010.665|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.06|    1233.7|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.09|  1282.436|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2017.12|   1290.82|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.03|  1412.007|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.06|  1488.055|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.09|  1497.678|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2018.12|  1570.507|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.03|  1393.749|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.06|  1517.143|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.09|  1381.514|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2019.12|  1370.985|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.03|  1073.017|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.06|  1131.445|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.09|  1440.101|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2020.12|  1489.979|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "|   BDCQ.SF1AA2CA|2021.03|  1390.782|      NULL|     F|Dollars|        6|Business Data Col...|Industry by finan...|Sales (operating ...|Forestry and Logging|Current prices|    Unadjusted|          NULL|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- Series_reference: string (nullable = true)\n",
      " |-- Period: double (nullable = true)\n",
      " |-- Data_value: double (nullable = true)\n",
      " |-- Suppressed: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- UNITS: string (nullable = true)\n",
      " |-- Magnitude: integer (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- Group: string (nullable = true)\n",
      " |-- Series_title_1: string (nullable = true)\n",
      " |-- Series_title_2: string (nullable = true)\n",
      " |-- Series_title_3: string (nullable = true)\n",
      " |-- Series_title_4: string (nullable = true)\n",
      " |-- Series_title_5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DisplayDataFrame\").getOrCreate()\n",
    "\n",
    "# Define the path to your CSV file\n",
    "csv_file_path = \"data.csv\" \n",
    "\n",
    "# Read the CSV file into a PySpark DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows:\")\n",
    "df.show()\n",
    "\n",
    "# Display the schema of the DataFrame\n",
    "print(\"Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       Data_value|\n",
      "+-------+-----------------+\n",
      "|  count|             6520|\n",
      "|   mean|4878.963066564418|\n",
      "| stddev|7248.031249367176|\n",
      "|    min|         -398.194|\n",
      "|    max|        41541.633|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"SummaryStatistics\").getOrCreate()\n",
    "\n",
    "# Define the path to your CSV file\n",
    "csv_file_path = \"data.csv\"  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Read the CSV file into a PySpark DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Choose the column for which you want to calculate summary statistics\n",
    "selected_column = \"Data_value\"  # Replace with the actual column name\n",
    "\n",
    "# Calculate summary statistics for the selected column\n",
    "column_summary = df.describe([selected_column])\n",
    "\n",
    "# Show the summary statistics\n",
    "column_summary.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDITIONAL QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         word|count|\n",
      "+-------------+-----+\n",
      "|        Vide,|    1|\n",
      "|          lex|    1|\n",
      "|institutionis|    1|\n",
      "|       vidit,|    1|\n",
      "|          Sed|    6|\n",
      "|         isti|    1|\n",
      "|         nova|    1|\n",
      "|         vera|    1|\n",
      "|          rei|    1|\n",
      "|      homini,|    1|\n",
      "|       dicam,|    1|\n",
      "|       quanta|    1|\n",
      "|        dixti|    1|\n",
      "|  voluptates?|    1|\n",
      "|       cogit.|    1|\n",
      "|        puto.|    3|\n",
      "|           ne|    3|\n",
      "|      inpune.|    1|\n",
      "|       quoque|    1|\n",
      "|      audivi,|    1|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Word with maximum occurrence: non\n",
      "Count of maximum occurrence: 17\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
    "\n",
    "# Define the path to your folder containing text files\n",
    "text_folder_path = \"resources/\"  # Replace with the actual path to your text files\n",
    "\n",
    "# Read text files into a PySpark DataFrame\n",
    "df = spark.read.text(text_folder_path)\n",
    "\n",
    "# Tokenize the words using the split function\n",
    "words_df = df.select(explode(split(df.value, \" \")).alias(\"word\"))\n",
    "\n",
    "# Calculate the count of each word\n",
    "word_counts = words_df.groupBy(\"word\").count()\n",
    "\n",
    "# Show the word counts\n",
    "word_counts.show()\n",
    "\n",
    "# Find the word with the maximum occurrence\n",
    "max_occurrence_word = word_counts.orderBy(\"count\", ascending=False).first()[\"word\"]\n",
    "max_occurrence_count = word_counts.orderBy(\"count\", ascending=False).first()[\"count\"]\n",
    "\n",
    "# Display the word with the maximum occurrence\n",
    "print(\"Word with maximum occurrence:\", max_occurrence_word)\n",
    "print(\"Count of maximum occurrence:\", max_occurrence_count)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
